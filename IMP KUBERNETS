https://infotechys.com/install-a-kubernetes-cluster-on-rhel-9/ == kubernets cluster installation process. take static-ip for nodes.

IMP:
if the developer are changeing the variables or any other environment variables/endpoints, we will get "CrashLoopBackOff" error.
kubectl.awseksdev02 get pods -n dev-kafka | grep -v Running ==> To see the pods who are having the issues(like above)

kubectl.awseksdev02 get deployments -A | grep -i 0/0 ==> to see deployments currents stage

kubectl == To connect to the kubernets cluster. It will check automatically "~/.kube/config/".

kubectl get nodes == This command pulls the data from ".kube/config", To know how many nodes in kubernets cluster.

kubectl version --short == To know the client version.

Kubectl config get-contexts ==> this command will shows the how many clusters are tagged to this dev server. Let connect to your jump server.

Kubectl config current-context ==> it will tell we are in which cluster.

kubectl config use-context arn:aws:eks:us-east-1:8756:cluster/awseksdev02 == to jump to required cluster.

Kubectl get nodes ==> This command will shows the what are the nodes connected to the cluster after logged in by useing above command.

kubectl describe pod <pod-name> -n <namespace> | grep -A 10 "Init Containers"  ==> is the command to check dyntrace is running.

Git branch -a ==> it will shows the all the branches, now we are in the “feature/fre-dev” branch. We will encourage the developer to put the final code in “feature/pre-dev” branch.

kubectl delete pod podname -n roboshop == To delete the pod without configaration file.

kubectl get all -A ==> to see name space with pods

kubectl logs podname -n roboshop == To see logs of a pod

kubectl get rs -n roboshop == To see the replicas

kubectl get deployments -n roboshop == To see the deploymentssets.

kubectl delete deployment nginx-deployment -n roboshop ==> to see deployment

kubectl delete ns roboshop == To delete the Namespace

aws eks list-clusters --output table ==> login to jump machine and switch to cldadmdv account and run this command,it will list created EKS clusetr in the AWS

YAML SYNTAX USAGE TO BUILD RESOURCES IN KUBERNETS
==================================================
apiVersion: == Every resource creates with the api version(v1).
kind: == what kind of resource you are creating.first letter is capital(kind: Namespace)
metadata: == metadata menas below information
  name: == That resource name(note in kind what ever we are giving that name)
  namespace: == whichname space are we creating pods
  labels: == labels are key=value pairs to call other services, labels have limitations in length and specal characters.
  annotatons: == annotations are used to call outside resource(aws secrats), annotations we there is no linit like variables, we can use special charecters as well.

spec: == it means container specifications
- name: == denotes the container name
  image: == denotes which image we are useing
  env:  == it denotes the environment variable for container. these are key=value pairs.
           ex - name: DEMO_GREETING
                value: "Hello from the environment"

            Note: Like this if there are many environment variables we will go for "configMap". This configMap we can use for N(number) of pods.
                  applications when it requires configaration information it will take from "configMap", configMap is nothing but a key=value pairs.
   resources: here we will define how much cpu and mem we required for the container.
              ex:     resources:
                        requests: == Denotes the how much cpu and memory is required while application start
                          cpu: "100m"
                          memory: "68mi"
                        limits: == Denotes the if application is having more load then what extend the resource limits will go.
                          cpu: "280m"
                          memory: "128mi"
=================================================================================

kubectl get namespaces == To see all namespaces in your kubernets

kubectl delete namespace roboshop ==  To delte the namespace.

kubectl create -f namespace.yaml == To create the the service whatever in "namespace.yaml" file.

kubectl delete -f namespace.yaml == To delte the service what ever we menationed in "namespace.yaml" file.

kubectl apply -f namespace.yaml == if resources not created it will create, if you assign any changes it will update.

kubectl get pods -n roboshop == To see the pods under roboshop namespace.

kubectl exec -it hello-pod -n roboshop bash == To login to pod

kubectl exec -it multi-container -c almalinux -n roboshop bash == If our pod is having multiple containers to login specificall almalinux container.

kubectl describe pod  multi-container -n roboshop == To know about the pod in detailed, like labels info, annotations info

kubectl apply --dry-run=client -f 01-cluster-ip.yaml == To validate syntax of the your file. it wont create anything. it is just dry run. This indicates that your YAML file is correctly configured and ready to apply in your Kubernetes cluster.

k9s installation in RHEL8 server
===================================
curl -LO https://github.com/derailed/k9s/releases/latest/download/k9s_Linux_amd64.tar.gz
tar -xvzf k9s_Linux_amd64.tar.gz
mv k9s /usr/local/bin/
chmod +x /usr/local/bin/k9s
k9s version
k9s == To see graphical view for all pods, namespaces etc...

:ns roboshop ==> to see pods in roboshop
===========================================================================================

 eksctl is the official command line from AWS, by useing "eksctl" we can configure production related clusters.

 eksctl create cluster --config-file=eks.yaml == This is the command to create cluster


===========================================================================================
@#### configMap == advantages of the configmap is if the values are changeing, we are not disturbing the pod. mostly for application code change we will go for cicd (or) build process. if there is no application code change we maintain configaration outside of the application code. then we will save lot of time. so we dont maintain environmental variables in docker, we will maintain in kubernets layer as configMap.
directly we can edit configMap and restart the configmap and restart the pods. automatically new values will fetch.the use of configMap is fetch the values dynamically. 

ex:- 
apiVersion: v1
  kind: ConfigMap
  metadata:
  name: devops-config(IT means configMap name)

data:  ==> it means what data we are giving, here we are giving key=pairs.
  course: devops
  trainer: "krishnareddy" (this information we needs to call to pods, where we required)

kubectl apply -f 07.configMap.yaml -n roboshop ==  To create configMap

kubectl get configmap -n roboshop == To see the configMap details.

kubectl describe configmap confimapname -n roboshop == To see what is in configmap.

=========== keep below info under the container to call configMap to any pod ===========
envFrom:
  - configMapRef:
       name: devops-config
===========================

kubectl edit configmap devops-config -n roboshop == To edit the configmap in server it self.
================================================================================================

@###Secrets in Kubernets == secrets and configmap both are same. just name will change. it is like key=value pair.
 Note: - in secrets we needs to give "base64" value.
        To get base64 value. in gitbash shell execute below commands.
        $ echo -n "admin"|base64
          YWRtaW4=
        $ echo -n "admin123"|base64
          YWRtaW4xMjM=

      To decode the above passwords use below commands.
        $ echo -n YWRtaW4xMjM= | base64 --decode
          admin123

ex: 
apiVersion: v1
kind: Secret
metadata: 
  name: devops-secret(It means secret name)

type: Opaque( it means we cont see that)
data:
  username: YWRtaW4=
  password: YWRtaW4xMjM=

kubectl get secrets -n roboshop == To see the secrets in roboshop name space.
=========== keep below info under the container to call configMap to any pod ==============
    envFrom:
      - secretRef:
          name: devops-secret
===========================================================================================

@###Services: Pod is dynamic(that means this minit it will run next minit pod will terminate), Pod ip address are aphemeral they are not perminent. to achive pod to pod communication in kubernets and to expose the pod to outside world pod must attach to the service.

1) we are useing pods but we are not exposing outside world, if you want to expose pods to outside other applications or outside world, we must use services.

2) Load balancing

3) service mesh

Three types of services
=========================
clusterIP -- It is purely internal to kubernets.

NodePort -- Node port you can expose your pod to outside world

Load balancer -- we can expse to outside world.use in AWS,AZURE,GCS.

IMP Notes
==========
1) first we have pod.
2) we need to attach this pod to service. here label will help to select particular pod to respective service. labels should be unique. below once shows the labels uniqueness. so our pod labels should be unique.
  
  project: roboshop
  component: catalogue
  tier: tier-2


1) ClusterIp: cluster ip for the internal purpus.
apiVersion: v1
kind: Service
metadata:
  name: nginx-service

spec:
         == Here if we are not giving anything here that means "cluster-ip"
  selector: (it means  once pod is created this service is going to attach with witch pod, that is nothing but selector, How it select? that is depends on the labels(in Pod), what are the labels we gave in pod, the same labels we needs to give in service also)
    app: nginx
    demo: krishna (in pod syntax what information we have give the same info 
          we needs to give, then only pod will select the respective service)

  ports:
    protocal: TCP
    port: 80 (service port) 
    targetPort: 80 (container Port, that means people hit service port, port number-80, that will pass the request to container port: 80) 

kubectl get services == To displays the all services in the kubernets.  

2) Nodeport:- if you want to expose your pod to outside world.for nodeport we will get cluster ip. so clusterip is subset of nodeport.

 =just add below lines to above synatx to become nodePort====
 spec:
  type: NodePort
  selector:

  nodeport we dont use.if you want completely external go for go for load balancer, if you want to internal go for cluster-ip. if you go for loadbalancer nodeport will come auomatically. nodeport means to expose the ipaddress of worker node. it is not good to use nodeport that is not correct. nodeport is internal concept in loadbalancer, with out node port loadbalancer will nort work.
=====================================

3) Load balancer:- Load balancer will use for cloud providers. for users directly we are not giving the ports ip address before that we are keeping loadbalancers. providing cluster-ip address to user is not a secure thing, so we keep loadbalancer. if user hits the loadbalncer, the request from the loadbalancer will go to any one of the nodeport via port number 31197 for the server, the nodeport request the cluster-ip, that cluster -ip send request to pod.

=just add below lines to above synatx to become Load Balancer====
spec:
  type: LoadBalancer            
  selector:
===========================================================================================
REPLICASET:- replicaset means same of pods. one pod is not enough to bare the load.based on the requests the pods needs to be scale. Pod is subset of replica set. first replica set will create. it will check it self for what we are creating replicas
 replicaset will refers to the labels, then witch pod is having the same labels for that pod. it will create replicas.
  matchlabels:
    app: nginx
    tier: frientend

ex:
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  namespace: roboshop
  labels:
    app: nginx
    tier: frontend

spec:
  replicas: 3 #it means three replicas we want
  selector:  # replica-set labels
    matchLabels:
      app: nginx
      tier: frontend
  
  template:   #it is pod defination, it dont have apiVersion: and kind: , the reason pod is subset of the replicaset.
    metadata:
      labels:
        app: nginx
        tier: frontend

    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80

Generally replicaset is for the to create number of replicas for the pod. we are useing application version(ex: cataloghu:1.0.0) is running, in next release we want to run (ex: cataloghu:1.2.0) for that needs to go re-release. in tis case we needs delete the existing one(kubectl delete -f applicationname.yaml) and recreate with the latest code(kubectl apply -f applicationname.yaml).

note: applicationname.yaml file should have upto date code.
====================================================================================================================================================
DEPLOYMENTSET:- ReplicaSet is manually used to maintain number of replicas, but it con't identify the changes in the application and con't update.
 "To identify the changes in the application and to update the version we have deployment".

imp:services(clusterIP < NodePort < LoadBalancer)
     sets(Pod < replicaset < deploymentset)

  ex: syntax same as replicaset just replace "kind: Deployment"

  so in deploymentset application is updated with the single command "kubectl apply -f filename.yaml"

  note: applicationname.yaml file should have upto date code.

  kubectl delete deployment nginx-deployment -n roboshop ==> to see deployment

  kubectl get  deployment -n roboshop == To see the deployments

  How deployment is working?
     old replicaset is creating the new replicaset. once pod in new replica set will up then pod in old replicaset will down, means at a time 3 pods will run because we set responsibulity is to replicaset is at any sitvation it has to run 3-replicas. like this new pods will create in new replicaset. finally replicaset is going to deleted. then new replicaset is going to attach to deploymentset. This process is called rooling update. This is zero down time deployment. but few seconds our application old version and new version both are running.
===========================================================================================
=====================================================================================================================================================================================
ROBOSHOP PROJECT:- for any project below two point are important.

1) image should exist (or) build the image ==> as per the application requirement build the image.
2) configaring image through manifest files ==> It means we are informing to kubernets how to run that image by manifest files.
          
          Here in kubernets first we build the image, that image we are pushing to dockerhub, after that we create kubernetes manifest files and informs how kubernets will run that image.

Q) who pull the images?
A) Kubernets cluster is pulling the images.

Below errors can expect by above two steps
------------------------------------------
image is there or not.
image build properly or not.
what are the image versions.
does image pushed to repositary(Nexus or dockerhub or ECS) or not.
kubernets is having image pull access or not.
once image pulled, then configaration changes(step-2) correct or not.

https://github.com/daws-76s/roboshop-documentation ==> for the project documentation

cat ~/.docker/config.json ==> to check which account is accessing latestly to the docker hub. here credentials are in base64.

docker info == To dispaly all information about docker including above authentication info.
======================
image pull policy: 
imagePullpolicy: Always ==> it means kubentes cluster everytime pulls the latest image from repository(ECR, dockerhub, etc), so always keep "Always" that is recamanded.

imagePullpolicy: ifNotPresent ==> Kubernetes pulls the image only if it is not already present on the node.

imagePullpolicy: Never ==> Kubernetes will never attempt to pull the image. It uses only the local copy.
==========================================================================================

To avoid multiple times giving "-n namespace", we can try below things.

git clone https://github.com/ahmetb/kubectx /opt/kubectx
ln -s /opt/kubectx/kubens /usr/local/bin/kubens
kubens roboshop ==> To move to roboshop namespace
kubectl get pods == for all commands we can execute under same namespace.

==========================================================================================

mongodb port no: 27017

[root@lenlk8smastert01 debug]# kubectl get pods -o wide
NAME                         READY   STATUS    RESTARTS   AGE    IP               NODE               NOMINATED NODE   READINESS GATES
catalogue-78cfc54744-r5l7d   1/1     Running   0          5h6m   192.168.58.241   lenlk8sworkert01   <none>           <none>
debug                        1/1     Running   0          11m    192.168.58.232   lenlk8sworkert01   <none>           <none>
mongodb-d8d59d9db-cv9m2      1/1     Running   0          20h    192.168.58.231   lenlk8sworkert01   <none>           <none>
[root@lenlk8smastert01 debug]#

as per this o/p catalogue is in one node and mongodb is another node etc.

root@mongodb-d8d59d9db-cv9m2:/# netstat - lntp # after login the pods executing this command, here mongodb  is running on port No: 27017
Active Internet connections (w/o servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State
tcp        0      0 mongodb-d8d59d9db:27017 192-168-58-241.ca:52560 ESTABLISHED
Active UNIX domain sockets (w/o servers)
Proto RefCnt Flags       Type       State         I-Node   Path
root@mongodb-d8d59d9db-cv9m2:/#
 

mysql works == 3306 port number

mysql -u shipping -pRoboShop@1 == After login to mysql pod, again login to mysql server
mysql> show databases; == It will displays the databases
mysql> use cities;
Database changed
mysql> show tables;
==============================================================================================

Q) What is statefull applications?
A) we have data in some applications those are called statefull applications, where the data is crucial..(or) applications where the storage is mandatary.

 below are examples.

    MONGODB --> when ever we are creating some users that stores in mongodb and redis.
    RABBIT MQ--> Whenever we are creating some order that will store in rabbitmq.
    MYSQL --> shipping related information will come from mysql.
    MONGODB--> Cataloghu where the product information will shared.

Q) What is stateless applications?
A) Applications where the storage is not mandatary, they are called stateless applications.
 ex:- catalog, cart, user and shipping etc.

Q) In kubernets server where the data is store?
A) The data is getting stored in EC2 worker nodes.

Q) we clearly pods are ephemeral(keep on changeing), so in kubernets "ec2 nodes are perminent or temparary?
A) Nodes are ephemeral, so if you start storing the crusial data in "ec2-worker' nodes, those nodes tomorrow may deleted. then we will
  loose data again. so you should not take statefull applications storing the data in worker nodes. in that case we should have some
  external storage. we should mount the 'storage(EBS/EFS)' to kubernets cluster. 

  The storage can be EBS/EFS.

  EBS --> is like HARD disk.
  EFS --> It is like NFS storage.

STORE THE DATA IN WORKER NODES (OR) KUBERNETS VOLUMES:
-----------------------------------------------------
1. EmptyDir
2. HostPath    --> these two things will use to store the data in worker node or internal volumes. this data is not perminent but we 
   have some use cases.

Q) What is EmptyDir in kubernets?
A) In sidecar concept we have two containers in side the pod. pod characterstics are multiple containers inside the pod share same 
    network and storage. one container is serving for the application and another container shifting the logs to ELK. 

    EmptyDir: emptyDir is used for sidecar pattern, we mount volume to the Sidecar and main container useing EmptyDir.as the name says this emptyDir volume is intially empty. All the containers in pod can read and write the same files in the emptyDir volume. when you create the emptyDir it will create the volume inside the node and it will give access to pod.

    EmptyDir is used in sidecar pattern to access the main container logs to ship it to the external logging system like elk.

     then sidecar get access to storage, so sidecar project have filebeat. filebeat is the public image for the for elastic search, we put filebeat in sidecar, this filebeat access the logs and ship. there is some configaration for the filebeat.

    i/p and 0/p --> input is for the prod logs to success, o/p is nothing but where to shift the logs.

    we have to inform filebeat, we can take filebeat images from the internet but we needs to give this configaration where to send the logs.

Q) Pods are aphermal so the pod may terminate do we have logs avilable?
A) we dont have logs if the pods are temparary. we will shift the logs to elastic search, but who will ship?
    Main pod responsebulity is sending response to requests, then we will keep sidecar, the purpus of the sidecar is it will access the
    storage and contineously shift logs to the ELK. That is usage of the sidecar.
 
 
Q) What is HOSTPATH?
A) In Ec2 /var/log/directory we have lot of logs, like pod logs these logs also very important to understand what is happening underline worker node. like to know worker node is connected to kubernets master? is anyone hacking the underlying nodes, how is 
monitaring for the underlying nodes, How is the cpu utilization these all things are important, so we needs to ship all those worker 
node logs to external system. How many worker nodes we have those many logs we needs to ship.

  Giving host path to specific directory, it is purely adminstrative task and you should give only read-only access. if you give write access pod can do anything in the host. Hostpath is dangerous but it can had a valid reason to ship the underline worker node logs to
  external system, we can configure host path with some precations like configaring a particular directory and as well as only read-only access. HERE DAEMONSET PLAYS wider role.

Q) How to write node-port is read-only?
A) we will declare in manifest file under volume mount.

    volumeMounts:
    - mountPath: /foo
      name: example-volume
      readOnly: True --> here we should give readly

Q) What is DaemonSet?
A) DaemonSet will make sure a pods runs in each and every worker node. if you delete one worker node that will gone automaticaly. if you add new node to the cluster a daemonset will automatically create the in that worker node. FLUENTD(From elk) will be deployed as a daemonset that can access the underlaying worker node logs and send them to elk. FLUENTED contains access to the /var/log directoryand shifts the logs to external system.
              How many worker nodes are there those many pods will created by daemonset without specifying the number. if you delete daeemonset all pods in worker node will be deleted.

Q) Uasges of DaemonSet?
A) 1) To configure storage to every node(Running a cluster storage daemon on every node)

   2) To push logs from every worker node( running a log collection daemon on every node)

   3) To Set monitaring to every node (Running a node monitaring daemon on every node)

ekctl delete cluster --config-file=eks.yaml --> To delete the cluster after the practice.


 Q) In one namespace we are deploying the all pods. in real time different namespaces we have then how?
    (or) WEB is in one namespace and APP is in another namespace, database is in different namespaces, then internally how they communicate?

  A) There is a communication between namespace to namespace. then service change bit different.
     with in namespace( web, app, Db) if we give service name that will connect. if there are different name spaces then.

     syntax: different namespace.svc.cluster.local
=============================================================================

EXTERNAL VOLUMES
----------------

external volumes like HARD DISK and CLOUD DRIVERS.

HARD DISK--> Near to computer as near as possible.

CLOUD DRIVERS--> Cloud drivers are network drivers.. like NFS..

if you store the data inside kubernets cluster or worker nodes that is defnetly not reliable, it may loose the data anytime. so we desided keep the storage outside.

IMP NOTE: "This Storage we needs to connect with cluster"

Generally to manage storage we required storage team, in cloud there is no big responsibulity. heavy lifting is to handle by AWS(or) cloud platforms. still kubernets adminstarter should know the storage concepts.

HERE we manage the storage by "STATIC PROVISIONING AND DYNAMIC PROVISIONING"

STATIC PROVISIONING
-------------------

Static provisioning means we needs to create the storage in onpramise. it is tuff to add disks and sync the data, but in cloud that is simple.

In static provisioning we have two types of volumes. they are EBS and EFS.

EBS -- EBS is nothing but Elastic block storagelike HARD DISK.

EFS -- EFS is nothing but ELASTIC FILE SYSTEM, it is like in NFS.

EBS(ELASTIC BLOCK STORAGE)
--------------------------
1) first we needs to create the storage, either storage admin or k8 admin will create the storage. our goal is we needs to store the data in outside, that outside is EBS.

Creating the EBS VOLUME
AWS--> ELASTIC BLOCK STORAGE --> VOLMES --> CREATE VOLUMES

VOLUME SETTINGS
volume type(General purpose SSD(gp3))
size(GIB)(100)
IOPS(3000)
avilable zone(us-east-1a)
snapshot ID - Optional( Dont create the volume from a snapshot)
                      create volume(enter)

CONDITION:- our servers are in which avilabulity zone, that avilabulity zone only we needs to creates the volumes.

Q) Can we create the volume in "us-east-1c"?

A) Availabulity zone is like datacenter where all servers to be present. so where the server is avilable there only we needs to create the EBS volume.

NOTE-1:- if server is avilable in "US-EAST-1B" and i created volume in "US-EAST-1C" that will not work in EBS.

NOTE-2:- We needs to make this EBS volume avilable for the "k8-cluster", for this we should install the "aws-ebs-csi" drivers should be installed( like to put pendrive or keyboard to laptop to detect it requires the drivers). for kubernets cluster external storages(EBS?EFS) to attach we should install the drivers.

Server:- kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.28" -- installing the driver.

NOTE-3:- EC2 instance and EBS both are different resources. so a proper role shouuld be attached to 'EC2' instance to access 'EBS'.
          To create EBS volume, To mount EBS volume and describe EBS volume , delete EBS volume..all these roles should have to EC2 instance. the reason is that they are different rosources.

AWS--> EC2 INSTANCE --> Security --> IAM Role(eksctl-roboshop-node group or any role) this role is attached to ec2 instance, this role all ready have some permissions by default but also add few more permissions.

Permissions --> Add permissions --> attach policy
other permissions policy(ec2 full access{search this})--> select Amazon EC2 full access( select this after this instance can create and delete volume everything)

ADD PERMISSIONS(Enter)

KUBERNETS VOLUME OBJECTS
------------------------
we have few volume related objects, how we have Pod,ConfigMap,Secrets, resource like for volume also we have few resource.

Kubernets is creating the persistence volume, this persistence volume will repracent the storage.

PERSISTENCE VOLUME(PV) --> persistence volume will repracent the storage, why it needs to repracent?
A) AS a kubernets adminstrater we dont have access to the EBS storage. Persistence volume work as a wrapper. if we do operations on the persistance volume kubernets in background do operations on the storage. So pv repracents the physical volume external to kubernets.

PERSISTENCE VOLUME CLAIM(PVC) --> claim means we needs to request something. so pods should request volume through PVC(Persistance volume claim). PVC is not like a physical repracentaion it is just like a request to the PV.
            To use EBS Volumes first we should create the 'PV', it is exactly equal to the EBS and then we have to claim pvc. pvc is like a claim.

IMP NOTE:- POD connect to the pvc and pvc connect to the PV.





